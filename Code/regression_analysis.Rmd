---
title: "regression_analysis"
output: html_document
date: "2023-04-07"
---

# Data Prep

First, lets bring in some packages.

```{r}
library(corrplot)
library(xts)
library(vctrs)
library(rlang)
library(kernlab)
library(crypto2)
library('lubridate')
library('dplyr')
library(reshape2)
library(glue)
library(qcc)
library(tidyverse)
library(data.table)
library(ggplot2)
library(DAAG)
library(caTools)
library(car)
library(quantmod)
library(MASS)
library(corrplot)
```

Now bring in the data:

```{r}
data.daily <- read.csv('../Data/data_daily.csv')[,-1]
data.hourly <- read.csv('../Data/data_hourly.csv')[,-1]
```

Next, lets drop the rows that have no information in the close column (due to the missing price data in the twitter input data. This was addressed in the data prep Rmd file.)

```{r}

data.hourly <-data.hourly[is.na(data.hourly$close) == F,]

data.hourly$datetime <- ymd_hms(data.hourly$datetime)
data.hourly$day <- ymd(data.hourly$day)

data.daily$day <- ymd(data.daily$day)
```

# Helper Functions

Next, as we did in our data exploration workbook, lets create a function that allows us to shift the close price *forward* n periods. That way, when we look at one row of data, we can say that the comment/tweet activity at time *t-n* is being compared against the closing price at time *t*.

```{r}
shift_df <- function(df, n){
  dfc <- data.table(copy(df))
  cols = c("close")
  anscols = paste("lead", cols, sep="_")

  dfc[order(day), (anscols) := shift(.SD, n, type="lead"), .SDcols=cols]
  dfc <- dfc %>% mutate(price_dif = lead_close - close)
  dfc <- dfc %>% mutate(price_dif_percent = round((lead_close/close) - 1,4))
  dfc <- dfc %>% mutate(price_dir = ifelse(price_dif >=0, 1,0))
  dfc <- dfc[1:(nrow(dfc)-n),]
  dfc
  
}


```

Now, we want to also aggregate hour independent data points back *d* amount of days. This allows us to answer the following: How does the sentiment over the last *d* days/hours impact the price of Bitcoin *n* days/hours from now?

Lets write another function that can do this transformation for us.

```{r}
agg_lag_df <- function(df, d){
  
  cols <- colnames(df)
  cols <- cols[! cols %in% c('close','lead_close')]
  e <- nrow(df)
  print(e)
  for (c in cols){
  vname <- glue('{c}')
    df <- df %>% 
      
        mutate( !!vname := roll_sum(.data[[c]], d, align = "right", fill = NA))
  }       

  df <- df[d + 1:(e-d),]
  df
}
```

Since we are going to want to test different lag/lead times to see if there is any difference in model performance, lets build another function that takes in:

-   The initial data frame (daily/hourly)

-   A formula

-   A list of intervals we want to test

This function will return a dataframe with one column being the interval tested and the other being the cross-validated r^2^ value.

```{r}
run_intervals <- function(df, form, N, response_var){
  
  for (n in N){
    mdf <- shift_df(df, n)
    m <- lm(formula(form), mdf)
    
    print(n)
    print(cross_validate(mdf, m, response_var))
  }
  
}

```

# Linear Regression Models

Below, we will build a series of models and evaluate each of them under the below assumptions:

Since we have 500 + rows and only 7 predictors, we can count out B. That leaves A.

Our model above failed to consider the assumptions of a linear model. These are:

1.  Collinearity

2.  Non-linearity of the response-predictor relationships (addressed in eda.Rmd)

3.  Correlation of error terms

4.  Non-constant variance of error terms

5.  Outliers

6.  High-leverage points

We will address each of these as we move through this documentation.

## Simple Linear-Linear Model

For our first model, we are going to look at only the features that we saw were strongly correlated with the price movements of Bitcoin.

```{r}
df.daily <- shift_df(data.daily, 1)[,c('lead_close',
           #'close',  
           'total_reddit', 
           'positive_reddit', 
           'neutral_reddit',
           'negative_reddit',  
           'total_tweets', 
           'positive_tweets', 
           'neutral_tweets',
           'negative_tweets')] %>% agg_lag_df(7)

daily.lin_lin <- lm(lead_close ~ ., data = df.daily)
summary(daily.lin_lin)

```

Our first model performed rather well - we can see here that .89% of the variance in bitcoin price is explained by how much people are talking about Bitcoin across reddit and Twitter the 7 days before. However, there are a few things that we need to consider before taking that at face value. First, we need to cross validate that model and ensure it was not overfit. We will do that now. We'll build a function we can reuse on other lin-lin models.

```{r}
cross_validate <- function(df, model){
  
      
    m.cv <- cv.lm(df, model, m=5, seed=10, printit=F, plotit =F)
    
    response_var <- summary(model)$call$formula[[2]]
    SSres <- attr(m.cv,"ms")*nrow(df)
    SStotal <- sum((df[[response_var]] - mean(df[[response_var]]))^2)
    rs <- 1- SSres/SStotal
    rs
  
}

cross_validate(df.daily, daily.lin_lin)


```

Looks like we get a warning here. Some quick research tells us that this error is telling us one of two things. Either A.) Two predictor variables are perfectly correlated or B.) You have more model parameters than observations in the dataset.

### Collinearity

The first assumption we will address is collinearity. That is, the assumption that our predictor variables are correlated to one another. Intuitively, we can assume that they are correlated. The features we are using are the total tweets which is just the total of the positive, negative, and neutral tweets, and for Reddit, the total comments This is why our cross validated model through the error:

    Warning: prediction from a rank-deficient fit may be misleading

Lets investigate this a little. First, we will

```{r}
plot(df.daily)
```

Visually inspecting this, we can see that multicolinearity is very strong across all of our predictor variables.

Lets first attempt to just remove the total columns, as they are just a combination of the others.

```{r}
df.daily <- shift_df(data.daily, 1)[,c('lead_close',
           'positive_reddit', 
           'neutral_reddit',
           'negative_reddit',
           'positive_tweets', 
           'neutral_tweets',
           'negative_tweets')] %>% agg_lag_df(7)

daily.lin_lin <- lm(lead_close ~ ., data = df.daily)
summary(daily.lin_lin)
vif(daily.lin_lin)
cross_validate(df.daily,daily.lin_lin)
```

Here we get an r^2^ of .6, but our VIF's are still large. Looking at the summary, only "negative tweets" has an obviously lower p value, so there's not one clear feature we would want to retain.

We have a couple of options here.

1.  Keep only one term, at random

2.  Add interaction terms

3.  Principal Component Analysis

In this exploration, we will try the latter two.

## Interaction Term

For this model, we will try using an interaction term.

For our interaction term, we will use the volume traded at period *t-n*. Logically, the amount price moves may be tied to not just how much people are talking about bitcoin, but also how is being traded. For example, people may be talking very negatively about bitcoin at a given moment, but what if no one is trading on this information?

```{r}

df.daily <- df.daily <- shift_df(data.daily, 1)[,c('lead_close',
           'volume',                                       
           'positive_reddit', 
           'neutral_reddit',
           'negative_reddit',
           'positive_tweets', 
           'neutral_tweets',
           'negative_tweets')] %>% agg_lag_df(7)

 daily.lin_lin.m2 <- lm(lead_close ~ 
                         positive_reddit*volume + 
                         negative_reddit*volume + 
                         neutral_reddit*volume  +
                         positive_tweets*volume +
                         neutral_reddit*volume + 
                         negative_tweets*volume, data = df.daily)
 summary(daily.lin_lin.m2)
 

```

### Collinearity

```{r}
vif(daily.lin_lin.m2)
```

Once again, while we have a very high R^2^ value, we also have very high VIF values still. As such, adding the closing price as an interaction term does not appear to have given us a better model.

## Principal Component Analysis

Now, we will instead try to reduce the number of variables by using prinicipal component analysis. This will take all of our features, make a linear combination of them, and give us a new set of features.

**Note:** PCA is outside of the scope of this assignment, so no further explanation will be delivered.

```{r}
# build a df with all columns, exluding the columns discussed above like total_comments, and the columns relating to bitcoin price. 


df.daily.all <- shift_df(data.daily, 1)[,c('lead_close',
           'volume',                                       
           'positive_reddit', 
           'neutral_reddit',
           'negative_reddit',
           'positive_tweets', 
           'neutral_tweets',
           'negative_tweets')]  %>% agg_lag_df(7)


#replace na's with 0
df.daily.all <- mutate_all(df.daily.all, ~replace_na(.,0))

#perform PCA
df.daily.all.pca <- prcomp(~.,df.daily.all[,!'lead_close'], scale = TRUE)



#scree plot
pca.var.per <- round(summary(df.daily.all.pca)$importance[2,]*100,1)
barplot(pca.var.per,
         main ="Scree Plot (Daily)",
         xlab= "Principal Component",
         ylab = "Percent Variation")
```

After looking at the resulting models, it appears that using 3 principal components actually gives us the strongest model, with diminishing returns after that. As such, we will build a model with 3 PCs and then evaluate the other assumptions.

```{r}
df.daily.all.pca.3 <- as.data.frame(cbind(df.daily.all.pca$x[,1:3],
                                      df.daily.all[,'lead_close']))
   
daily.lin_lin.pca <- lm(lead_close~. ,
                        data = df.daily.all.pca.3)

summary(daily.lin_lin.pca)
print('VIF:')
vif(daily.lin_lin.pca)
cross_validate(df.daily.all.pca.3,daily.lin_lin.pca)

```

Now, we have a model with a r^2^ of .71, and all VIF are below 5, indicating no multicollinearity! Only thing left to do now is to cross validate the model:

```{r}
cross_validate(df.daily.all.pca.3,daily.lin_lin.pca)
```

#### Correlation of error terms

An important assumption is that error terms e1, e2, \...,en are uncorrelated. If they aren't, then we have autocorrelation. To check this, we will perform a Durbin Watson Test.

```{r}
durbinWatsonTest(daily.lin_lin.pca)
```

Our p value is 0, which means we can reject the null hypothesis and conclude that the residuals in this regression model are autocorrelated.

Why is this? Durbin- Watson statistic is only suitable for ordered time or spatial series. Because we transformed our data into cross section variables with PCA, we cannot use it to detect autocorrelation. <https://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0146865&type=printable>

Citation: Chen Y (2016) Spatial Autocorrelation Approaches to Testing Residuals from Least Squares Regression. PLoS ONE 11(1): e0146865. <doi:10.1371/journal.pone.0146865>

The impact of autocorrelation on PCA and PCA-based SPC is neither well understood nor properly documented. As such, for the purposes of this paper, we will ignore this assumption.

<https://onlinelibrary.wiley.com/doi/full/10.1002/qre.1858>

Vanhatalo, E., and  Kulahci, M. (2016)  Impact of Autocorrelation on Principal Components and Their Use in Statistical Process Control. *Qual. Reliab. Engng. Int.*,  32:  1483-- 1500. doi: [10.1002/qre.1858](https://doi.org/10.1002/qre.1858 "Link to external resource: 10.1002/qre.1858").

#### Heteroskedasticity (non-constant variance of error terms)

```{r}
plot(daily.lin_lin.pca, which=1)
```

Here, we can see that there is not a strong pattern emerging. There is some drift towards the end, however, it is not strongly correlated outside of a few observations. As such, we conclude our model does not violate this assumption.

In addition to heteroskedacity, we also want to check and see if our residuals are normally distirubted and if they are spread equally along the range of fitted values.

```{r}
plot(daily.lin_lin.pca, which=c(2, 3))
```

Here we can see there is not too much skewness in our residuals, meaning our model is performing well across our entire dataset. We do see some skewness emerge towards the right of the Q-Q plot, however, it only appears to be a few points, and thus may be cause by outliers. Otherwise, the residuals have a pseudo normal distribution.

#### Outliers and High Leverage Points

```{r}
plot(daily.lin_lin.pca, which=c(4, 5))
```

Lastly, we look at outliers and leverage. On the first chart, we have two points that seem to be outliers, as their cooks distance is greater than .5. We note that one of the points, 121, is the same point on the Q-Q plot that fell outside of a normall distributed range for residuals. However, looking at the leverage plot, there are no points that appear to be high leverage outliers. This means we could likely remove these points and not have much of an impact on the model. Thus, we conclude that the points are outliers, but are not impacting the overall model and do not need to be removed.

## Simple linear Model- Less Variables

In this model, we will attempt a very simple model, removing most of the variables in attempt to reduce collinearity and see if it holds up to other assumptions.

```{r}
df.daily.all <- shift_df(data.daily, 1)[,c('lead_close',
           'volume',                                       
           'total_reddit',
           'total_tweets')] %>% agg_lag_df(7)
total_models <- lm(lead_close ~ volume +total_reddit+ total_tweets, df.daily.all)
vif(total_models)
summary(total_models)
plot(total_models)
cross_validate(df.daily.all,total_models)
durbinWatsonTest(total_models)
```

Here, we see the VIF

# Hourly Models

## Simple Linear Regression

In this section, we will perform the same models as above but using the hourly data rather than the daily. The analysis of each model will be the same as above, and will not be elaborated for each model unless a highly succesful model is found.

```{r}

df.hourly <- mutate_all(data.hourly, ~replace_na(.,0))

df.hourly <- shift_df(data.hourly, 1)[,c('lead_close',
           'positive_reddit', 
           'neutral_reddit',
           'negative_reddit',
           'positive_tweets', 
           'neutral_tweets',
           'negative_tweets')] %>% agg_lag_df(6)

hourly.lin_lin <- lm(lead_close ~ ., data = df.hourly)
summary(hourly.lin_lin)
cross_validate(df.hourly, hourly.lin_lin)
vif(hourly.lin_lin)
plot(hourly.lin_lin)
```

## Interaction Term

```{r}

names(data.hourly)[names(data.hourly) == 'volume..btc.'] <- 'volume'
df.hourly <- shift_df(data.hourly, 1)[,c('lead_close',
           'volume',                                       
           'positive_reddit', 
           'neutral_reddit',
           'negative_reddit',
           'positive_tweets', 
           'neutral_tweets',
           'negative_tweets')] %>% agg_lag_df(6)

hourly.lin_lin <- lm(lead_close ~ 
                         positive_reddit*volume + 
                         negative_reddit*volume + 
                         neutral_reddit*volume  +
                         positive_tweets*volume +
                         neutral_reddit*volume + 
                         negative_tweets*volume, data = df.hourly)
 summary(hourly.lin_lin)
 vif(hourly.lin_lin)
 plot(hourly.lin_lin)
 

```

## Principal Component Analysis

```{r}

df.hourly.all <- shift_df(data.hourly, 1)[,c('lead_close',
           'volume',                                       
           'positive_reddit', 
           'neutral_reddit',
           'negative_reddit',
           'positive_tweets', 
           'neutral_tweets',
           'negative_tweets')] %>% agg_lag_df(6)

#replace na's with 0
df.hourly.all <- mutate_all(df.hourly.all, ~replace_na(.,0))

#perform PCA
df.hourly.all.pca <- prcomp(~.,df.hourly.all[,!'lead_close'], scale = TRUE)



#scree plot
pca.var.per <- round(summary(df.hourly.all.pca)$importance[2,]*100,1)
barplot(pca.var.per,
         main ="Scree Plot",
         xlab= "Principal Component",
         ylab = "Percent Variation")
```

```{r}
df.hourly.all.pca.4 <- as.data.frame(cbind(df.hourly.all.pca$x[,1:4],
                                      df.hourly.all[,'lead_close']))
   
hourly.lin_lin.pca <- lm(lead_close~. ,
                        data = df.hourly.all.pca.4)

summary(hourly.lin_lin.pca)
vif(hourly.lin_lin.pca)
plot(hourly.lin_lin.pca)
cross_validate(df.hourly.all.pca.4, hourly.lin_lin.pca)
```

## Simple Model - Less Variables

```{r}
df.hourly.all <- shift_df(data.hourly, 1)[,c('lead_close',
           'volume',                                       
           'total_reddit',
           'total_tweets')] %>% agg_lag_df(6)
total_models <- lm(lead_close ~ volume +total_reddit+ total_tweets,
                   df.hourly.all)
vif(total_models)
summary(total_models)
plot(total_models)
cross_validate(df.hourly.all,total_models)
```

```{r}
run_intervals <- function(df, form, N){
  r2 <- c()
  for (n in N){
    mdf <- shift_df(df, n)
    m <- lm(formula(form), mdf)
    
    print(summary(m)$r.squared)
    r2[n] <- summary(m)$r.squared
    r2
  }
  
}
```

```{r}
intervals <- run_intervals(data.daily,
              form = 'log(lead_close) ~ volume +total_reddit+ total_tweets',
              N = c(1,12,18,24))


```

```{r}

```
