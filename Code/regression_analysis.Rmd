---
title: "regression_analysis"
output: html_document
date: "2023-04-07"
---

# Data Prep

First, lets bring in some packages.

```{r}
library(corrplot)
library(xts)
library(vctrs)
library(rlang)
library(kernlab)
library(crypto2)
library('lubridate')
library('dplyr')
library(reshape2)
library(glue)
library(qcc)
library(tidyverse)
library(data.table)
library(ggplot2)
library(DAAG)
library(caTools)

library(quantmod)
library(MASS)
library(corrplot)
```

Now bring in the data:

```{r}
data.daily <- read.csv('../Data/data_daily.csv')[,-1]
data.hourly <- read.csv('../Data/data_hourly.csv')[,-1]
```

Next, lets drop the rows that have no information in the close column (due to the missing price data in the twitter input data. This was addressed in the data prep Rmd file.)

```{r}

data.hourly <-data.hourly[is.na(data.hourly$close) == F,]

data.hourly$datetime <- ymd_hms(data.hourly$datetime)
data.hourly$day <- ymd(data.hourly$day)

data.daily$day <- ymd(data.daily$day)
```

Next, as we did in our data exploration workbook, lets create a function that allows us to shift the close price *forward* n periods. That way, when we look at one row of data, we can say that the comment/tweet activity at time *t-n* is being compared against the closing price at time *t*.

```{r}
shift_df <- function(df, n){
  dfc <- data.table(copy(df))
  cols = c("close")
  anscols = paste("lead", cols, sep="_")

  dfc[order(day), (anscols) := shift(.SD, n, type="lead"), .SDcols=cols]
  dfc <- dfc %>% mutate(price_dif = lead_close - close)
  dfc <- dfc %>% mutate(price_dif_percent = round((lead_close/close) - 1,4))
  dfc <- dfc %>% mutate(price_dir = ifelse(price_dif >=0, 1,0))
  dfc <- dfc[1:(nrow(dfc)-n),]
  dfc
  
}

```

# Helper Functions

Since we are going to want to test different lag/lead times to see if there is any difference in model performance, lets build another function that takes in:

-   The initial data frame (daily/hourly)

-   A formula

-   A list of intervals we want to test

This function will return a dataframe with one column being the interval tested and the other being the cross-validated r^2^ value.

```{r}
run_intervals <- function(df, form, response_var,N){
  
  for (n in N){
    mdf <- shift_df(df, n)
    m <- lm(formula(form), mdf)
    
    print(n)
    print(cross_validate(mdf, m, response_var))
  }
  
}

```

Lets build another function that can help reduce variable in the model. This function will take in a model and a maximum p value, and return a new formula object with only the variable with p values from the inputed model that are below the filter value.

```{r}
write_formula <- function(lm_model, pvalue_filter) {
        coeff <- data.frame(pvalue = (summary(lm_model)$coefficients)[-1,4])
        
        response_var <- summary(lm_model)$call$formula[[2]]
        
        formula <- (paste(glue("{response_var} ~ "), paste(rownames(filter(coeff, pvalue < pvalue_filter)), collapse = " + "))
        )
return(formula)
}
```

```{r}
run_intervals(data.daily,
              form = 'lead_close ~ 
                       total_reddit +
                       positive_reddit + 
                       negative_reddit + 
                       total_tweets +
                       positive_tweets +
                       negative_tweets',
              response_var = 'lead_close',
              N = c(1,7,14,21))

```

# Linear Regression Models

For our first model, we are going to look at only the features that we saw were strongly correlated with the price movements of Bitcoin.

```{r}
df.daily <- shift_df(data.daily, 1)[,c('lead_close',
           #'close',  
           'total_reddit', 
           'positive_reddit', 
           'neutral_reddit',
           'negative_reddit',  
           'total_tweets', 
           'positive_tweets', 
           'neutral_tweets',
           'negative_tweets')]

daily.lin_lin <- lm(lead_close ~ ., data = df.daily)
summary(daily.lin_lin)

```

Our first model performed rather well - we can see here that .61% of the variance in bitcoin price is explained by how much people are talking about Bitcoin across reddit and Twitter the day before. However, there are a few things that we need to consider before taking that at face value. First, we need to cross validate that model and ensure it was not overfit. We will do that now. We'll build a function we can reuse on other lin-lin models.

```{r}
cross_validate <- function(df, model){
  
      
    m.cv <- cv.lm(df, model, m=5, seed=10, printit=F, plotit =F)
    
    response_var <- summary(model)$call$formula[[2]]
    SSres <- attr(m.cv,"ms")*nrow(df)
    SStotal <- sum((df[[response_var]] - mean(df[[response_var]]))^2)
    rs <- 1- SSres/SStotal
    rs
  
}

cross_validate(df.daily, daily.lin_lin)


```

Looks like we get a warning here. Some quick research tells us that this error is telling us one of two things. Either A.) Two predictor variables are perfectly correlated or B.) You have more model parameters than observations in the dataset.

Since we have 500 + rows and only 7 predictors, we can count out B. That leaves A.

Our model above failed to consider the assumptions of a linear model. These are: 		

1.  Collinearity

2.  Non-linearity of the response-predictor relationships

3.  Correlation of error terms

4.  Non-constant variance of error terms

5.  Outliers

6.  High-leverage points

We will address each of these as we move through this documentation.

## Collinearity

The first assumption we will address is collinearity. That is, the assumption that our predictor variables are correlated to one another. Intuitively, we can assume that they are correlated. The features we are using are the total tweets which is just the total of the positive, negative, and neutral tweets, and for Reddit, the total comments This is why our cross validated model through the error:

    Warning: prediction from a rank-deficient fit may be misleading

Lets investigate this a little. First, we will

```{r}
plot(df.daily)
```

Visually inspecting this, we can see that multicolinearity is very strong across all of our predictor variables. We can confrim this using variance inflation factors.

```{r}
vif(daily.lin_lin)
```

All of these have significant VIF values (above \~5). Lets first attempt to just remove the total columns, as they are just a combination of the others.

```{r}
df.daily <- shift_df(data.daily, 1)[,c('lead_close',
           'positive_reddit', 
           'neutral_reddit',
           'negative_reddit',
           'positive_tweets', 
           'neutral_tweets',
           'negative_tweets')]

daily.lin_lin <- lm(lead_close ~ ., data = df.daily)
summary(daily.lin_lin)
vif(daily.lin_lin)
```

Here we get an r^2^ of .6, but our VIF's are still large. Looking at the summary, only "negative tweets" has an obviously lower p value, so there's not one clear feature we would want to retain.

We have a couple of options here.

1.  Keep only one term, at random

2.  Add interaction terms

3.  Principal Component Analysis

In this exploration, we will try the latter two.

### Interaction Term

For our interaction term, we will use the volume traded at period *t-n*. Logically, the amount price moves may be tied to not just how much people are talking about bitcoin, but also how is being traded. For example, people may be talking very negatively about bitcoin at a given moment, but what if no one is trading on this information?

```{r}

df.daily <- df.daily <- shift_df(data.daily, 1)[,c('lead_close',
           'volume',                                       
           'positive_reddit', 
           'neutral_reddit',
           'negative_reddit',
           'positive_tweets', 
           'neutral_tweets',
           'negative_tweets')]

 daily.lin_lin.m2 <- lm(lead_close ~ 
                         positive_reddit*volume + 
                         negative_reddit*volume + 
                         neutral_reddit*volume  +
                         positive_tweets*volume +
                         neutral_reddit*volume + 
                         negative_tweets*volume, data = df.daily)
 summary(daily.lin_lin.m2)
 vif(daily.lin_lin.m2)

```

Once again, while we have a very high R^2^ value, we also have very high VIF values still. As such, adding the closing price as an interaction term does not appear to have given us a better model.

### Principal Component Analysis

Now, we will instead try to reduce the number of variables by using prinicipal component analysis. This will take all of our features, make a linear combination of them, and give us a new set of features. Because we can now use a very large number of correlated variables, we will also bring in the dis-aggregated subreddit sentiment values. i.e rather than looking at just the total comments, we will look at the communities those comments were made in.

**Note:** PCA is outside of the scope of this assignment, so no further explanation will be delivered.

```{r}
# build a df with all columns, exluding the columns discussed above like total_comments, and the columns relating to bitcoin price. 
df.daily.all <- shift_df(data.daily, 1)[,!c('day','open','high','close','high',
                                 'low','total_tweets','total_reddit','market_cap',
                                 'sent_negatives','Sent_positives',
                                 'percent_pos_reddit','percent_neg_reddit',
                                 'percent_pos_twitter', 'price_dif',
                                 'price_dif_percent','price_dir')]
#replace na's with 0
df.daily.all <- mutate_all(df.daily.all, ~replace_na(.,0))

#perform PCA
df.daily.all.pca <- prcomp(~.,df.daily.all[,!'lead_close'], scale = TRUE)



#scree plot
pca.var.per <- round(summary(df.daily.all.pca)$importance[2,]*100,1)
barplot(pca.var.per[1:25],
         main ="Scree Plot",
         xlab= "Principal Component",
         ylab = "Percent Variation")
```

Looking at the above scree plot, the first 3 principal components account for around 80% of the total variance. Lets build a linear model using different numbers of principal components to confirm this.

```{r}
r2 <- c()

for (i in 1:20){
   linear_data <- as.data.frame(cbind(df.daily.all.pca$x[,1:i],
                                      df.daily.all[,'lead_close']))
   
   pca.model <- lm(lead_close~.,data = linear_data)
   r2[i] <- summary(pca.model)$r.squared
}
plot(r2)
```

After looking at the resulting models, it appears that using 7 principal components actually gives us the strongest model, with diminishing returns after that. As such, we will build a model with 7 PCs and then evaluate the other assumptions.

```{r}
df.daily.all.pca.seven <- as.data.frame(cbind(df.daily.all.pca$x[,1:7],
                                      df.daily.all[,'lead_close']))
   
daily.lin_lin.pca <- lm(lead_close~. ,
                        data = df.daily.all.pca.seven)

summary(daily.lin_lin.pca)
vif(daily.lin_lin.pca)
```

Now, we have a model with a r^2^ of .71, and all VIF are below 5, indicating no multicollinearity! Only thing left to do now is to cross validate the model:

```{r}
cross_validate()
```
